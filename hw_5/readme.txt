Задание:
1. Доработать паука в имеющемся проекте, чтобы он складывал все записи в БД (любую) и формировал item по структуре:
[наименование вакансии;
зарплата от;
зарплата до;
ссылка на саму вакансию;
сайт, откуда собрана вакансия.](http://)
2. Создать в имеющемся проекте второго паука по сбору вакансий с сайта superjob. Паук должен формировать item по
    аналогичной структуре и складывать данные в БД.
3. Взять любую категорию товаров на сайте Леруа Мерлен. Собрать с использованием ItemLoader следующие данные:
        название;
        все фото;
        параметры товара в объявлении.
4. С использованием output_processor и input_processor реализовать очистку и преобразование данных. Цены должны быть
    в виде числового значения.
5. * Написать универсальный обработчик параметров объявлений, который будет формировать данные вне зависимости от их
    типа и количества.
6. * Реализовать более удобную структуру для хранения скачиваемых фотографий.



Внезапно оказалось, что это 5 и 6 дз в одной.

1, 2: поскольку я изначально реализовал парсинг hh.ru и superjob.ru в одном алгоритме,
смысл второго паука пропадает: однако его можно легко добавить - в нужных местах воткнул комментарии-заглушки
с псевдокодом. +в settings можно назначить приоритеты для пайплайнов, но вроде это не обязательно.

3. Done.

4. Минимально необходимая обработка проведена. Дальнейшая очистка данных видится целесообразной таргетно при добавлении
    в БД, если она вообще необходима. Можно дополнительно очистить два параметра: "время нагрева" и "Диаметр трубы
    подключения (дюйм)"

5. Параметры товара парсятся в два списка: названия параметров и значения параметров. При этом проводится первичная
    обработка значений - отрезаются пробелы по бокам строки. Затем преобразуются в пары ключ-значение.
    Дальнейший парсинг и обработка происходят на стадии добавления в БД.

6. Изображения скачиваются в images/{артикул товара}/